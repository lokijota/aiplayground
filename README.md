# Jota's "AI" playground - simple learning experiments

Tests and experiences. Mostly Python with models running locally in ollama.

# Experiments

- [Model completions calling either using http requests or with OpenAI's library, inc structured outputs and image understanding](01.ModelCalling/README.md)
- [Langchain tutorials and examples](02.Langchain/README.md) (WIP)

# To-do list

- do a langgraph sample (eg for prompt improvement? use R1 and see https://www.deeplearning.ai/short-courses/reasoning-with-o1/)
- test autogen / multi-LLM scenario
- function calling (eg with geocaching as example)
- mistral small (inc function calling) - https://colab.research.google.com/drive/1zo794DObJNXwj3ohJHx6dI0ALUV0rJYu?usp=sharing
- summarization (inc data source parsing: txt, md, pdf, word, onenote)
- embeddings (using different models, inc. tests with hiearchical retrieval)
- chunking (simple by text size, semantic by heading, with overlaps)
- retrieval (more to test the above? optional)
- try HF's smolagents (and watch https://www.youtube.com/watch?v=c8EpB4zmXG0&t=18s&ab_channel=SamWitteveen)
- explore PocketPal or a way to run a quantized model in the phone / summarize geocaching logs
- Jamba (possible start point: https://www.deeplearning.ai/short-courses/build-long-context-ai-apps-with-jamba/)

# Stuffs

- [General hints, links and notes](GeneralNotes.md)
- [Tutorials or other things to try](TutorialsAndLinks.md)
